{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple example for performing symbolic regression for a set of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T11:58:13.702218433Z",
     "start_time": "2024-06-20T11:58:11.882159447Z"
    }
   },
   "outputs": [],
   "source": [
    "from nesymres.architectures.model import Model\n",
    "from nesymres.utils import load_metadata_hdf5\n",
    "from nesymres.dclasses import FitParams, NNEquation, BFGSParams\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import torch\n",
    "from sympy import lambdify\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T11:58:13.876208804Z",
     "start_time": "2024-06-20T11:58:13.710739674Z"
    }
   },
   "outputs": [],
   "source": [
    "## Load equation configuration and architecture configuration\n",
    "import omegaconf\n",
    "with open('100M/eq_setting.json', 'r') as json_file:\n",
    "  eq_setting = json.load(json_file)\n",
    "\n",
    "cfg = omegaconf.OmegaConf.load(\"100M/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T11:58:13.876651146Z",
     "start_time": "2024-06-20T11:58:13.743265386Z"
    }
   },
   "outputs": [],
   "source": [
    "## Set up BFGS load rom the hydra config yaml\n",
    "bfgs = BFGSParams(\n",
    "        activated= cfg.inference.bfgs.activated,\n",
    "        n_restarts=cfg.inference.bfgs.n_restarts,\n",
    "        add_coefficients_if_not_existing=cfg.inference.bfgs.add_coefficients_if_not_existing,\n",
    "        normalization_o=cfg.inference.bfgs.normalization_o,\n",
    "        idx_remove=cfg.inference.bfgs.idx_remove,\n",
    "        normalization_type=cfg.inference.bfgs.normalization_type,\n",
    "        stop_time=cfg.inference.bfgs.stop_time,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T11:58:13.876908871Z",
     "start_time": "2024-06-20T11:58:13.743788952Z"
    }
   },
   "outputs": [],
   "source": [
    "params_fit = FitParams(word2id=eq_setting[\"word2id\"], \n",
    "                            id2word={int(k): v for k,v in eq_setting[\"id2word\"].items()}, \n",
    "                            una_ops=eq_setting[\"una_ops\"], \n",
    "                            bin_ops=eq_setting[\"bin_ops\"], \n",
    "                            total_variables=list(eq_setting[\"total_variables\"]),  \n",
    "                            total_coefficients=list(eq_setting[\"total_coefficients\"]),\n",
    "                            rewrite_functions=list(eq_setting[\"rewrite_functions\"]),\n",
    "                            bfgs=bfgs,\n",
    "                            beam_size=cfg.inference.beam_size #This parameter is a tradeoff between accuracy and fitting time\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T11:58:13.877135043Z",
     "start_time": "2024-06-20T11:58:13.744462028Z"
    }
   },
   "outputs": [],
   "source": [
    "weights_path = \"../weights/100M.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T11:58:14.289208028Z",
     "start_time": "2024-06-20T11:58:13.744865659Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbrugger/.virtualenvs/NeuralSymbolicRegressionThatScales_NewNew/lib/python3.10/site-packages/pytorch_lightning/utilities/migration/migration.py:208: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.3.3 to v2.3.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../weights/100M.ckpt`\n"
     ]
    }
   ],
   "source": [
    "## Load architecture, set into eval mode, and pass the config parameters\n",
    "model = Model.load_from_checkpoint(weights_path, cfg=cfg.architecture)\n",
    "model.eval()\n",
    "if torch.cuda.is_available(): \n",
    "  model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T11:58:14.289555597Z",
     "start_time": "2024-06-20T11:58:14.217680832Z"
    }
   },
   "outputs": [],
   "source": [
    "fitfunc = partial(model.fitfunc,cfg_params=params_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T11:58:14.289876556Z",
     "start_time": "2024-06-20T11:58:14.218123087Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create points from an equation\n",
    "number_of_points = 500\n",
    "n_variables = 1\n",
    "\n",
    "#To get best results make sure that your support inside the max and mix support\n",
    "max_supp = cfg.dataset_train.fun_support[\"max\"] \n",
    "min_supp = cfg.dataset_train.fun_support[\"min\"]\n",
    "X = torch.rand(number_of_points,len(list(eq_setting[\"total_variables\"])))*(max_supp-min_supp)+min_supp\n",
    "X[:,n_variables:] = 0\n",
    "target_eq = \"x_1*sin(x_1)\" #Use x_1,x_2 and x_3 as independent variables\n",
    "X_dict = {x:X[:,idx].cpu() for idx, x in enumerate(eq_setting[\"total_variables\"])} \n",
    "y = lambdify(\",\".join(eq_setting[\"total_variables\"]), target_eq)(**X_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T11:58:14.291459854Z",
     "start_time": "2024-06-20T11:58:14.235098616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  torch.Size([500, 3])\n",
      "y shape:  torch.Size([500])\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape: \", X.shape)\n",
    "print(\"y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T11:58:15.853194617Z",
     "start_time": "2024-06-20T11:58:14.249695493Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbrugger/NeuralSymbolicRegressionThatScales/src/nesymres/architectures/model.py:136: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X,device=self.device).unsqueeze(0)\n",
      "/home/jbrugger/NeuralSymbolicRegressionThatScales/src/nesymres/architectures/model.py:140: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y,device=self.device).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint of the encoder: 4.096e-05GB \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbrugger/.virtualenvs/NeuralSymbolicRegressionThatScales_NewNew/lib/python3.10/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n"
     ]
    }
   ],
   "source": [
    "output = fitfunc(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T11:58:15.853925599Z",
     "start_time": "2024-06-20T11:58:15.852095961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'all_bfgs_preds': ['((x_1)*(sin(x_1)))', '((x_1)*((cos(x_1))*(tan(x_1))))'],\n 'all_bfgs_loss': [0.0, 5.1156677e-14],\n 'best_bfgs_preds': ['((x_1)*(sin(x_1)))'],\n 'best_bfgs_loss': [0.0]}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class Namespace():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "args = Namespace()\n",
    "args.logging_level = 40\n",
    "args.max_branching_factor = 2\n",
    "args.max_depth_of_tree = 10\n",
    "args.max_constants_in_tree = 5\n",
    "args.number_equations = 10\n",
    "args.max_num_nodes_in_syntax_tree = 30\n",
    "args.num_calls_sampling = 10\n",
    "args.sample_with_noise = False\n",
    "args.how_to_select_node_to_delete = 'random'\n",
    "\n",
    "args.precision = 'float32'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T11:58:15.982946017Z",
     "start_time": "2024-06-20T11:58:15.852421675Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T11:58:16.030645443Z",
     "start_time": "2024-06-20T11:58:15.867315143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* x_1 sin x_1  \n"
     ]
    }
   ],
   "source": [
    "best_eqution = output['best_bfgs_preds'][0]\n",
    "from src.equation_classes.infix_to_prefix import  InfixToPrefix\n",
    "from src.syntax_tree.syntax_tree import SyntaxTree\n",
    "\n",
    "tree = SyntaxTree(grammar=None, args=args)\n",
    "\n",
    "obj = InfixToPrefix(possible_operator_2dim='/ * - + root'.split(),\n",
    "                    possible_operator_1dim='ln sin'.split(),\n",
    "                    possible_operands='')\n",
    "for symbol in tree.operator_to_class.keys(): \n",
    "    best_eqution = best_eqution.replace(f'{symbol}', f' {symbol} ')\n",
    "best_eqution = best_eqution.replace('(', ' ( ')\n",
    "best_eqution = best_eqution.replace(')', ' ) ')\n",
    "best_eqution = best_eqution.replace('x_1', ' x_1 ')\n",
    "best_eqution = best_eqution.replace('x_0', ' x_0 ')\n",
    "prefix = obj.infixToPrefix(best_eqution.split())\n",
    "print(prefix)\n",
    "tree.prefix_to_syntax_tree(prefix.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d: 0  id: 0     *\n",
      "d: 1  id: 1.0   \tx_1\n",
      "d: 1  id: 512.0 \tsin\n",
      "d: 2  id: 513.0 \t\tx_1\n"
     ]
    }
   ],
   "source": [
    "tree.print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T11:58:16.043722869Z",
     "start_time": "2024-06-20T11:58:15.976235569Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "FloatingPointError",
     "evalue": "divide by zero encountered in divide",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFloatingPointError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(X\u001B[38;5;241m.\u001B[39mnumpy(), columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx_0\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx_1\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx_2\u001B[39m\u001B[38;5;124m'\u001B[39m,])\n\u001B[1;32m      3\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m y \n\u001B[0;32m----> 4\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresidual\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m res\n",
      "File \u001B[0;32m~/NeuralSymbolicRegressionThatScales/src/syntax_tree/syntax_tree.py:384\u001B[0m, in \u001B[0;36mSyntaxTree.residual\u001B[0;34m(self, node_id, dataset)\u001B[0m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m node_to_evaluate\u001B[38;5;241m.\u001B[39minvertible:\n\u001B[1;32m    380\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_constants(call_node_id\u001B[38;5;241m=\u001B[39mnode_id,\n\u001B[1;32m    381\u001B[0m                        dataset\u001B[38;5;241m=\u001B[39mdataset,\n\u001B[1;32m    382\u001B[0m                        mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresidual\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    383\u001B[0m                        )\n\u001B[0;32m--> 384\u001B[0m     residual \u001B[38;5;241m=\u001B[39m \u001B[43mnode_to_evaluate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmath_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresidual\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    385\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcall_node_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnode_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    387\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstants_in_tree\u001B[49m\n\u001B[1;32m    388\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    389\u001B[0m     residual_32 \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfloat32(residual)\n\u001B[1;32m    390\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(np\u001B[38;5;241m.\u001B[39misfinite(residual_32)):\n",
      "File \u001B[0;32m~/NeuralSymbolicRegressionThatScales/src/equation_classes/math_class/sine.py:32\u001B[0m, in \u001B[0;36mSine.residual\u001B[0;34m(self, call_node_id, dataset, kwargs)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mresidual\u001B[39m(\u001B[38;5;28mself\u001B[39m, call_node_id, dataset, kwargs):\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m call_node_id \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode\u001B[38;5;241m.\u001B[39mnode_id:\n\u001B[0;32m---> 32\u001B[0m         p \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparent_node\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmath_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresidual\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m p\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m call_node_id \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode\u001B[38;5;241m.\u001B[39mlist_children[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mnode_id:\n",
      "File \u001B[0;32m~/NeuralSymbolicRegressionThatScales/src/equation_classes/math_class/multiplication.py:49\u001B[0m, in \u001B[0;36mMultiplication.residual\u001B[0;34m(self, call_node_id, dataset, kwargs)\u001B[0m\n\u001B[1;32m     47\u001B[0m     p \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode\u001B[38;5;241m.\u001B[39mparent_node\u001B[38;5;241m.\u001B[39mmath_class\u001B[38;5;241m.\u001B[39mresidual(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode\u001B[38;5;241m.\u001B[39mnode_id, dataset, kwargs)\n\u001B[1;32m     48\u001B[0m     c_0 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode\u001B[38;5;241m.\u001B[39mlist_children[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmath_class\u001B[38;5;241m.\u001B[39mevaluate_subtree(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode\u001B[38;5;241m.\u001B[39mnode_id, dataset, kwargs)\n\u001B[0;32m---> 49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdivide\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc_0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat64\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m call_node_id \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode\u001B[38;5;241m.\u001B[39mnode_id:\n\u001B[1;32m     51\u001B[0m     p \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode\u001B[38;5;241m.\u001B[39mparent_node\u001B[38;5;241m.\u001B[39mmath_class\u001B[38;5;241m.\u001B[39mresidual(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode\u001B[38;5;241m.\u001B[39mnode_id, dataset, kwargs)\n",
      "\u001B[0;31mFloatingPointError\u001B[0m: divide by zero encountered in divide"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(X.numpy(), columns=['x_0','x_1','x_2',])\n",
    "df['y'] = y \n",
    "res = tree.residual(512, dataset=df)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T11:58:16.417018502Z",
     "start_time": "2024-06-20T11:58:16.020006008Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-20T11:58:16.382738933Z"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f8fd71b98b163a0965b3204c263be7b56efe89ac907df8b2c30eb28f29cbfb8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
